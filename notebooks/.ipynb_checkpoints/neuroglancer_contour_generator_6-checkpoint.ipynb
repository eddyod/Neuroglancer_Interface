{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting dklab@192.168.1.12:3306\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import neuroglancer\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "#os.environ['NG_REPO_DIR'] = '/home/alexn/neuroglancer_interface/'\n",
    "#sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "sys.path.append(os.path.join('/home/eddyod/programming/pipeline_utility'))\n",
    "#from utilities.imported_atlas_utilities import *\n",
    "from utilities.contour_utilities import image_contour_generator, add_structure_to_neuroglancer\n",
    "#from filepath_manager import *\n",
    "\n",
    "# sys.path.append(os.path.join( filepaths_dict['activebrainatlas_repo_utilities_fp'] ))\n",
    "# from utilities2015 import *\n",
    "# from registration_utilities import *\n",
    "# from annotation_utilities import *\n",
    "# from metadata import *\n",
    "# from data_manager import *\n",
    "\n",
    "\n",
    "color_map_file = os.path.join('../json_cache', 'struct_to_color_2.json')\n",
    "with open( color_map_file, 'r') as json_file:\n",
    "    structure_to_color = json.load( json_file )\n",
    "\n",
    "stack_param_file = os.path.join('../json_cache', 'stack_parameters_ng.json')\n",
    "with open( stack_param_file, 'r') as json_file:\n",
    "    stack_parameters_ng = json.load( json_file )\n",
    "    \n",
    "color_segments=[]\n",
    "for i in range(1,29):\n",
    "    color_segments.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = 'MD585'\n",
    "detector_id = 19\n",
    "# detector_id = 799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = 'MD589'\n",
    "detector_id = 19\n",
    "# detector_id = 799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = 'MD594'\n",
    "detector_id = 19\n",
    "# detector_id = 799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroglancer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Replace: viewer = neuroglancer.Viewer()\n",
    "#With: \n",
    "neuroglancer.set_server_bind_address('0.0.0.0')\n",
    "viewer = neuroglancer.Viewer()\n",
    "print(viewer)\n",
    "\n",
    "ip_name = !hostname -I\n",
    "print('http://' + ip_name[0].strip() + ':' + viewer.get_viewer_url().split(':')[2]) ##Remote URL\n",
    "\n",
    "ip_name_str = str(ip_name).replace('\\'','').replace('\\\"','').replace('[','').replace(']','')\n",
    "real_ip = ip_name_str.split(' ')[0]\n",
    "print('http://' + real_ip + ':' + viewer.get_viewer_url().split(':')[2]) ##Remote URL\n",
    "\n",
    "viewer # port 41989, IP 132.239.73.85\n",
    "\n",
    "\n",
    "\n",
    "# Sets 'Image' layer to be prep2 images from S3 of <stack>\n",
    "with viewer.txn() as s:\n",
    "    s.layers['image'] = neuroglancer.ImageLayer(source='precomputed://https://activebrainatlas.ucsd.edu/data/MD589/neuroglancer_data/C1')\n",
    "    \n",
    "    # Resets X/Y/Z plane orientation\n",
    "    #s.navigation.pose.orientation = [0,0,0,1]\n",
    "    # Zooms out \n",
    "#     s.navigation.zoomFactor = 10000 # If 4panel\n",
    "    #s.navigation.zoomFactor = 5000 # If xy\n",
    "    \n",
    "    # Resets 3D Viewer Orientation\n",
    "    #s.perspectiveOrientation = [0,0,0,1]\n",
    "    # Zooms out\n",
    "    #s.perspectiveZoom = 75000\n",
    "    \n",
    "    s.layout = 'xy' # '3d'/'4panel'/'xy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets 'Image' layer to be prep2 images from S3 of <stack>\n",
    "with viewer.txn() as s:\n",
    "    s.layers['image'] = neuroglancer.ImageLayer(source='precomputed://https://mousebrainatlas-datajoint-jp2k.s3.amazonaws.com/precomputed/'+stack+'_fullres')\n",
    "    \n",
    "    # Resets X/Y/Z plane orientation\n",
    "    s.navigation.pose.orientation = [0,0,0,1]\n",
    "    # Zooms out \n",
    "#     s.navigation.zoomFactor = 10000 # If 4panel\n",
    "    s.navigation.zoomFactor = 5000 # If xy\n",
    "    \n",
    "    # Resets 3D Viewer Orientation\n",
    "    s.perspectiveOrientation = [0,0,0,1]\n",
    "    # Zooms out\n",
    "    s.perspectiveZoom = 75000\n",
    "    \n",
    "    s.layout = 'xy' # '3d'/'4panel'/'xy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroglancer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD594 DONE\n",
    "https://neuroglancer-demo.appspot.com/#!%7B%22layers%22:%5B%7B%22source%22:%22precomputed://https://mousebrainatlas-datajoint-jp2k.s3.amazonaws.com/precomputed/MD594_fullres%22%2C%22type%22:%22image%22%2C%22name%22:%22image%22%7D%2C%7B%22source%22:%22precomputed://https://s3.amazonaws.com/test-bucket-sid/final_precomputed_volumes/MD594%22%2C%22type%22:%22segmentation%22%2C%22name%22:%22annotation%22%7D%5D%2C%22navigation%22:%7B%22pose%22:%7B%22position%22:%7B%22voxelSize%22:%5B460%2C460%2C20000%5D%2C%22voxelCoordinates%22:%5B5392%2C6736%2C125.56800079345703%5D%7D%7D%2C%22zoomFactor%22:14720%7D%2C%22perspectiveOrientation%22:%5B0.08709775656461716%2C0.01880049705505371%2C0.026741867884993553%2C0.9956632852554321%5D%2C%22perspectiveZoom%22:131072%2C%22selectedLayer%22:%7B%22layer%22:%22annotation%22%7D%2C%22layout%22:%224panel%22%7D\n",
    "\n",
    "# MD585 DONE\n",
    "https://neuroglancer-demo.appspot.com/#!%7B%22layers%22:%5B%7B%22source%22:%22precomputed://https://mousebrainatlas-datajoint-jp2k.s3.amazonaws.com/precomputed/MD585_fullres%22%2C%22type%22:%22image%22%2C%22name%22:%22image%22%7D%2C%7B%22source%22:%22precomputed://https://test-bucket-sid.s3.amazonaws.com/final_precomputed_volumes/MD585%22%2C%22type%22:%22segmentation%22%2C%22name%22:%22annotation%22%7D%5D%2C%22navigation%22:%7B%22pose%22:%7B%22position%22:%7B%22voxelSize%22:%5B460%2C460%2C20000%5D%2C%22voxelCoordinates%22:%5B4816%2C6179%2C101.56800079345703%5D%7D%7D%2C%22zoomFactor%22:14720%7D%2C%22perspectiveOrientation%22:%5B0.0019906109664589167%2C-0.0022145232651382685%2C0.007156445644795895%2C0.9999699592590332%5D%2C%22perspectiveZoom%22:131072%2C%22selectedLayer%22:%7B%22layer%22:%22annotation%22%7D%2C%22layout%22:%224panel%22%7D\n",
    "\n",
    "# MD589\n",
    "https://neuroglancer-demo.appspot.com/#!%7B%22layers%22:%5B%7B%22source%22:%22precomputed://https://mousebrainatlas-datajoint-jp2k.s3.amazonaws.com/precomputed/MD589_fullres%22%2C%22type%22:%22image%22%2C%22name%22:%22image%22%7D%2C%7B%22source%22:%22precomputed://https://test-bucket-sid.s3.amazonaws.com/final_precomputed_volumes/MD589%22%2C%22type%22:%22segmentation%22%2C%22name%22:%22annotation%22%7D%5D%2C%22navigation%22:%7B%22pose%22:%7B%22position%22:%7B%22voxelSize%22:%5B460%2C460%2C20000%5D%2C%22voxelCoordinates%22:%5B9745%2C6531%2C170.47999572753906%5D%7D%7D%2C%22zoomFactor%22:14720%7D%2C%22perspectiveOrientation%22:%5B0.0019906109664589167%2C-0.0022145232651382685%2C0.007156445644795895%2C0.9999699592590332%5D%2C%22perspectiveZoom%22:131072%2C%22selectedLayer%22:%7B%22layer%22:%22annotation%22%7D%2C%22layout%22:%224panel%22%7D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thumbnail_volume_origin_wrt_wholebrain_10um [147.  98. 182.]\n"
     ]
    }
   ],
   "source": [
    "# CREATE VOLUMES STRUCTURE BY STRUCTURE\n",
    "\n",
    "structure = '3N_R'\n",
    "# # color_codes{'blue:'1,'red',2,'yellow':3}\n",
    "\n",
    "str_contour, first_sec, last_sec = image_contour_generator(stack, detector_id, structure, use_local_alignment=True, image_prep=2, threshold=0.2)\n",
    "\n",
    "# plt.imshow(ng_structure_volume_normal[20,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_structure_to_neuroglancer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d5b482b96f65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ng_structure_volume_normal = add_structure_to_neuroglancer( viewer, str_contour, structure, stack, first_sec, last_sec, \\\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                      \u001b[0mcolor_radius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxy_ng_resolution_um\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                      \u001b[0msolid_volume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_offset_big_volume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                      return_with_offsets=False, add_to_ng=True, human_annotation=False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'add_structure_to_neuroglancer' is not defined"
     ]
    }
   ],
   "source": [
    "ng_structure_volume_normal = add_structure_to_neuroglancer( viewer, str_contour, structure, stack, first_sec, last_sec, \\\n",
    "                                                     color_radius=5, xy_ng_resolution_um=10, threshold=0.2, color=5, \\\n",
    "                                                     solid_volume=False, no_offset_big_volume=False, save_results=False, \\\n",
    "                                                     return_with_offsets=False, add_to_ng=True, human_annotation=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Aligned Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CREATE VOLUMES STRUCTURE BY STRUCTURE\n",
    "\n",
    "# structure = '12N'\n",
    "# # color_codes{'blue:'1,'red',2,'yellow':3}\n",
    "\n",
    "# str_contour, first_sec, last_sec = image_contour_generator( stack, detector_id, structure, use_local_alignment=True, image_prep=2, threshold=0.2)\n",
    "\n",
    "# ng_structure_volume_normal = add_structure_to_neuroglancer( viewer, str_contour, structure, stack, first_sec, last_sec, \\\n",
    "#                                                     color_radius=5, xy_ng_resolution_um=10, threshold=0.2, color=5, \\\n",
    "#                                                     solid_volume=False, no_offset_big_volume=False, save_results=False, \\\n",
    "#                                                     return_with_offsets=False, add_to_ng=True, human_annotation=False)\n",
    "\n",
    "# plt.imshow(ng_structure_volume_normal[20,:,:])\n",
    "\n",
    "\n",
    "for structure in all_structures_total:\n",
    "    str_contour, first_sec, last_sec = image_contour_generator( stack, detector_id, structure, use_local_alignment=True, image_prep=2, threshold=0.2)\n",
    "\n",
    "    add_structure_to_neuroglancer( viewer, str_contour, structure, stack, first_sec, last_sec, \\\n",
    "                                  color_radius=5, xy_ng_resolution_um=10, threshold=0.2, color=1, \\\n",
    "                                  solid_volume=False, no_offset_big_volume=False, save_results=False,\\\n",
    "                                  return_with_offsets=False, add_to_ng=True, human_annotation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CRAETE ENTIRE BRAIN VOLUME\n",
    "xy_ng_resolution_um = 5\n",
    "\n",
    "with open('struct_reverse_2.json', 'r') as json_file:\n",
    "    structure_to_color = json.load( json_file )\n",
    "\n",
    "    \n",
    "# MD585: x_um = 35617,           y_um = 26086\n",
    "# MD585: x_pixels_.46res = x_um*0.46,  y_pixels_.46res = y_um*0.46\n",
    "# MD585: x_pixels_newres = x_pixels_.46res*(0.46/newres), y_pixels_newres = y_pixels_.46res*(0.46/newres)\n",
    "# microns/resolution\n",
    "y_voxels = int( 26086*0.46*(.46/xy_ng_resolution_um) + 0.5)\n",
    "x_voxels = int( 35617*0.46*(.46/xy_ng_resolution_um) + 0.5)\n",
    "full_brain_volumes = np.zeros((268,y_voxels,x_voxels), dtype=np.uint8)\n",
    "\n",
    "for structure in all_structures_total:\n",
    "    str_contour, first_sec, last_sec = image_contour_generator( stack, detector_id, structure, use_local_alignment=True, image_prep=2, threshold=0.5)\n",
    "    \n",
    "    try:\n",
    "        color=structure_to_color[structure]\n",
    "    except:\n",
    "        color=2\n",
    "    \n",
    "    str_volume, xyz_offsets = add_structure_to_neuroglancer( viewer, str_contour, structure, stack, first_sec, last_sec, \\\n",
    "                                          color_radius=5, xy_ng_resolution_um=xy_ng_resolution_um, threshold=0.5, color=color, \\\n",
    "                                          solid_volume=False, no_offset_big_volume=True, save_results=False, return_with_offsets=True, \\\n",
    "                                          add_to_ng=False, human_annotation=False )\n",
    "    \n",
    "    z_len, y_len, x_len = np.shape(str_volume)\n",
    "    full_brain_volumes[0:z_len, 0:y_len, 0:x_len] += str_volume\n",
    "\n",
    "\n",
    "\n",
    "color_segments=[]\n",
    "for i in range(1,50):\n",
    "    color_segments.append(i)\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    #s.layers[ display_name ] = neuroglancer.SegmentationLayer(\n",
    "    s.layers[ \"full_brain\" ] = neuroglancer.SegmentationLayer(\n",
    "        source = neuroglancer.LocalVolume(\n",
    "            data=full_brain_volumes, # Z,Y,X\n",
    "            voxel_size=[ xy_ng_resolution_um*1000, xy_ng_resolution_um*1000,20000], # X Y Z\n",
    "            voxel_offset = [ 0, 0, 0] # X Y Z\n",
    "        ),\n",
    "        segments = color_segments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_array = np.ones((1,80,80), dtype=np.uint8)\n",
    "color_array[0,0:49,0]= np.array(color_segments)\n",
    "color_array[0,0,0:49]= np.array(color_segments)\n",
    "\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    #s.layers[ display_name ] = neuroglancer.SegmentationLayer(\n",
    "    s.layers[ \"color_test\" ] = neuroglancer.SegmentationLayer(\n",
    "        source = neuroglancer.LocalVolume(\n",
    "            data= color_array, # Z,Y,X\n",
    "            voxel_size=[ 50000, 50000,200000], # X Y Z\n",
    "            voxel_offset = [ 0, 0, 0] # X Y Z\n",
    "        ),\n",
    "        segments = color_segments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Annotation Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if stack==\"MD585\":\n",
    "    hand_annotations = load_hdf_v2(atlas_data_root+'/CSHL_labelings_v3/MD585/MD585_annotation_contours_05312018041032_prep2_corr2.hdf')\n",
    "if stack==\"MD589\":\n",
    "    hand_annotations = load_hdf_v2(atlas_data_root+'/CSHL_labelings_v3/MD589/MD589_annotation_contours_05312018031718_prep2_corr1.hdf')\n",
    "if stack==\"MD594\":\n",
    "    hand_annotations = load_hdf_v2(atlas_data_root+'/CSHL_labelings_v3/MD594/MD594_annotation_contours_05312018035134_prep2_corr1.hdf')\n",
    "\n",
    "num_annotations = len(hand_annotations)\n",
    "\n",
    "def get_dense_coordinates( coor_list ):\n",
    "    dense_coor_list = []\n",
    "    # Shortest distance, x, y\n",
    "\n",
    "    #for x, y in coor_list:\n",
    "    for i in range(len(coor_list)-1):\n",
    "        x, y = coor_list[i]\n",
    "        x_next, y_next = coor_list[i+1]\n",
    "        \n",
    "        x_mid = (x+x_next)/2\n",
    "        y_mid = (y+y_next)/2\n",
    "        \n",
    "        \n",
    "        dense_coor_list.append([x,y])\n",
    "        dense_coor_list.append( [x_mid, y_mid] )\n",
    "        \n",
    "        if i==len(coor_list)-2:\n",
    "            dense_coor_list.append( [x_next, y_next] )\n",
    "            x, y = coor_list[0]\n",
    "            x_mid = (x+x_next)/2\n",
    "            y_mid = (y+y_next)/2\n",
    "            dense_coor_list.append( [x_mid, y_mid] )\n",
    "        \n",
    "    return dense_coor_list\n",
    "\n",
    "def get_contours_from_annotations( stack, target_str, densify=0 ):\n",
    "    str_contours_annotation = {}\n",
    "\n",
    "    for i in range(num_annotations):\n",
    "        structure = hand_annotations['name'][i]\n",
    "        side = hand_annotations['side'][i]\n",
    "        section = hand_annotations['section'][i]\n",
    "        \n",
    "        if side=='R' or side=='L':\n",
    "            structure = structure+'_'+side\n",
    "            \n",
    "        if structure==target_str:\n",
    "            vertices = hand_annotations['vertices'][i]\n",
    "            \n",
    "            for i in range(densify):\n",
    "                vertices = get_dense_coordinates( vertices )\n",
    "            \n",
    "            # Skip sections before the 22nd prep2 section for MD585 as there are clear errors\n",
    "#             if stack=='MD585' and section < MD585_ng_section_min-22:\n",
    "#                 #vertices = vertices - np.array(MD585_abberation_correction)\n",
    "#                 continue\n",
    "\n",
    "            str_contours_annotation[section] = {}\n",
    "            str_contours_annotation[section][structure] = {}\n",
    "            str_contours_annotation[section][structure][1] = vertices\n",
    "\n",
    "    first_sec = np.min(str_contours_annotation.keys())\n",
    "    last_sec = np.max(str_contours_annotation.keys())\n",
    "    \n",
    "    return str_contours_annotation, first_sec, last_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_structures_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f7cece30d668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtarget_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_structures_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# for target_str in all_structures_total:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure_to_color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_structures_total' is not defined"
     ]
    }
   ],
   "source": [
    "for target_str in all_structures_total[0:9]:\n",
    "# for target_str in all_structures_total:\n",
    "    color = structure_to_color[target_str]\n",
    "    \n",
    "    \n",
    "    str_contours_annotation, first_sec, last_sec = get_contours_from_annotations( stack, target_str, densify=4 )\n",
    "\n",
    "    ng_structure_volume = add_structure_to_neuroglancer( viewer, str_contours_annotation, target_str, stack, first_sec, last_sec, \\\n",
    "                                                    color_radius=2, xy_ng_resolution_um=5, threshold=1, color=color, \\\n",
    "                                                    solid_volume=False, no_offset_big_volume=True, save_results=False, \\\n",
    "                                                    return_with_offsets=False, add_to_ng=True, human_annotation=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_volume_fp( stack, precomputed=False, human_annotated=True, volume_type='structure', brain_crop='brainstem', \\\n",
    "                  xy_res=5, z_res=20, offset=False, color_scheme=1, thickness_scheme=1, structure=\"12N\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for target_str in all_structures_total[0:3]:\n",
    "for target_str in all_structures_total:\n",
    "    str_contours_annotation, first_sec, last_sec = get_contours_from_annotations( stack, target_str, densify=4 )\n",
    "\n",
    "    ng_structure_volume = add_structure_to_neuroglancer( viewer, str_contours_annotation, target_str, stack, first_sec, last_sec, \\\n",
    "                                                    color_radius=3, xy_ng_resolution_um=10, threshold=1, color=4, \\\n",
    "                                                    solid_volume=False, no_offset_big_volume=False, save_results=False, \\\n",
    "                                                    return_with_offsets=False, add_to_ng=True, human_annotation=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add all annotated brains to the viewer\n",
    "xy_ng_resolution_um = 5\n",
    "color_radius = 3\n",
    "\n",
    "for target_str in all_structures_total:\n",
    "    print(target_str)\n",
    "    str_contours_annotation, first_sec, last_sec = get_contours_from_annotations( stack, target_str, densify=4 )\n",
    "    \n",
    "    try:\n",
    "        color=structure_to_color[target_str]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        color=4\n",
    "    \n",
    "    ng_structure_volume = add_structure_to_neuroglancer( \\\n",
    "                            viewer, str_contours_annotation, target_str, stack, first_sec, last_sec, \\\n",
    "                            color_radius=color_radius, xy_ng_resolution_um=xy_ng_resolution_um, threshold=1, color=color, \\\n",
    "                            solid_volume=False, no_offset_big_volume=True, save_results=False, \\\n",
    "                            return_with_offsets=False, add_to_ng=True, human_annotation=True  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dic = {}\n",
    "color_num = 1\n",
    "\n",
    "for i in range(len(all_structures_total)):\n",
    "    str = all_structures_total[i]\n",
    "#     color_dic[]\n",
    "\n",
    "    if '_L' in str or '_R' in str:        \n",
    "        # Structure is _L and has _R right after\n",
    "        if '_L' in str:\n",
    "            color_dic[str] = color_num\n",
    "            color_num += 1\n",
    "        if '_R' in str:\n",
    "            color_dic[str] = color_num\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        color_dic[str] = color_num\n",
    "        color_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add all annotated brains to the viewer\n",
    "xy_ng_resolution_um = 5\n",
    "color_radius = 3\n",
    "\n",
    "prep2_img_width_um = stack_parameters_ng[stack]['image_width_um']\n",
    "prep2_img_height_um = stack_parameters_ng[stack]['image_height_um']\n",
    "\n",
    "prep2_section_min = stack_parameters_ng[stack]['prep2_section_min']\n",
    "prep2_section_max = stack_parameters_ng[stack]['prep2_section_max']\n",
    "\n",
    "# x_um = prep2_img_width_um                        y_um = prep2_img_height_um\n",
    "# x_pixels_.46res = x_um*0.46                      y_pixels_.46res = y_um*0.46\n",
    "# x_pixels_newres = x_pixels_.46res*(0.46/newres)  y_pixels_newres = y_pixels_.46res*(0.46/newres)\n",
    "# microns/resolution\n",
    "y_voxels = 1+int( prep2_img_height_um*0.46*(.46/xy_ng_resolution_um) + 0.5)\n",
    "x_voxels = 1+int( prep2_img_width_um*0.46*(.46/xy_ng_resolution_um) + 0.5)\n",
    "z_voxels = 10 + (prep2_section_max - prep2_section_min) # 268\n",
    "full_brain_volume_annotated = np.zeros((z_voxels,y_voxels,x_voxels), dtype=np.uint8)\n",
    "\n",
    "for target_str in all_structures_total:\n",
    "# for target_str in['VCA_L','7n_R','7n_L']:\n",
    "    print(target_str)\n",
    "    str_contours_annotation, first_sec, last_sec = get_contours_from_annotations( stack, target_str, densify=4 )\n",
    "    \n",
    "    try:\n",
    "        color=structure_to_color[target_str]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        color=4\n",
    "    \n",
    "    str_volume, xyz_str_offsets = add_structure_to_neuroglancer( \\\n",
    "                            viewer, str_contours_annotation, target_str, stack, first_sec, last_sec, \\\n",
    "                            color_radius=color_radius, xy_ng_resolution_um=xy_ng_resolution_um, threshold=1, color=color, \\\n",
    "                            solid_volume=False, no_offset_big_volume=True, save_results=False, \\\n",
    "                            return_with_offsets=True, add_to_ng=False, human_annotation=True  )\n",
    "    \n",
    "    z_len, y_len, x_len = np.shape(str_volume)\n",
    "#     full_brain_volume_annotated[0:z_len, 0:y_len, 0:x_len] = str_volume.copy()\n",
    "    for z in range( xyz_str_offsets[2], z_len ):\n",
    "        for y in range( xyz_str_offsets[1], y_len ):\n",
    "            for x in range( xyz_str_offsets[0], x_len ):\n",
    "                structure_val = str_volume[z, y, x]\n",
    "                if structure_val==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        full_brain_volume_annotated[z, y, x] = structure_val\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "    \n",
    "with viewer.txn() as s:\n",
    "    s.layers[ stack+\"_Atlas\" ] = neuroglancer.SegmentationLayer(\n",
    "        source = neuroglancer.LocalVolume(\n",
    "            data=full_brain_volume_annotated, # Z,Y,X\n",
    "            voxel_size=[ xy_ng_resolution_um*1000, xy_ng_resolution_um*1000,20000], # X Y Z\n",
    "            voxel_offset = [ 0, 0, 0] # X Y Z\n",
    "        ),\n",
    "        segments = color_segments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_annotation_fp = NEUROGLANCER_ROOT+stack+'/human_annotation/solid_volume_'+str(xy_ng_resolution_um)+'um/'\n",
    "full_annotation_fn = full_annotation_fp+'volume_colored.npy'\n",
    "print('Saving to :'+full_annotation_fp+full_annotation_fn)\n",
    "\n",
    "if not os.path.exists( full_annotation_fp ):\n",
    "    os.makedirs(full_annotation_fp)\n",
    "    \n",
    "np.save( full_annotation_fn, full_brain_volume_annotated )\n",
    "# radius <= 1 : wire\n",
    "#>radius <= 2 : thin\n",
    "#>radius <= 3.5 : ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layers[ stack+\"_Atlas\" ] = neuroglancer.SegmentationLayer(\n",
    "        source = neuroglancer.LocalVolume(\n",
    "            data=full_brain_volume_annotated, # Z,Y,X\n",
    "            voxel_size=[ xy_ng_resolution_um*1000, xy_ng_resolution_um*1000,20000], # X Y Z\n",
    "            voxel_offset = [ 0, 0, 0] # X Y Z\n",
    "        ),\n",
    "        segments = color_segments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir /home/alexn/Desktop/neuroglancer_binary_volumes/human_annotations_5um/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! aws s3 rm --recursive s3://test-bucket-sid/alex_neuroglancer_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEUROGLANCER_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! aws s3 cp --recursive $NEUROGLANCER_ROOT s3://test-bucket-sid/alex_neuroglancer_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 cp s3://test-bucket-sid/alex_neuroglancer_volumes/MD585/human_annotation/solid_volume_5um/volume_colored.npy /media/alexn/BstemAtlasDataBackup/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Neuroglancer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the viewer\n",
    "with viewer.txn() as s:\n",
    "    # Resets X/Y/Z plane orientation\n",
    "    s.navigation.pose.orientation = [0,0,0,1]\n",
    "    # Zooms out \n",
    "    s.navigation.zoomFactor = 10000\n",
    "    \n",
    "    # Resets 3D Viewer Orientation\n",
    "    s.perspectiveOrientation = [0,0,0,1]\n",
    "    # Zooms out\n",
    "    s.perspectiveZoom = 75000\n",
    "    \n",
    "    # Not necessary, just restates the voxel sizes of the image\n",
    "    s.navigation.pose.position.voxelSize = [460,460,20000]\n",
    "    # Sets Viewer's center location\n",
    "    s.navigation.pose.position.voxelCoordinates = [8192,6000,134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wholeslice_to_brainstem = -from_padded_to_wholeslice, from_padded_to_brainstem\n",
    "\n",
    "#from_padded_to_wholeslice\n",
    "rostral_limit = 50\n",
    "caudal_limit = 1188\n",
    "dorsal_limit = 21\n",
    "ventral_limit = 738\n",
    "\n",
    "#from_padded_to_brainstem\n",
    "rostral_limit = 521\n",
    "caudal_limit = 1057\n",
    "dorsal_limit = 128\n",
    "ventral_limit = 465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_volumes = '/home/alexn/Desktop/neuroglancer_binary_volumes/volumes_'+xy_ng_resolution_um+'um/'\n",
    "np.save( fp_volumes+structure+'_volume.npy',structure_volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
